<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description"
          content="SSNLP 2023">
    <meta name="author" content="">
    <meta name="keywords"
          content="SSNLP 2023, Singapore Symposium">
    <title>SSNLP 2023: The 2023 Singapore Symposium on Natural Language Processing
    </title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/scrolling-nav.css" rel="stylesheet">

    <link rel="shortcut icon" type="image/x-icon" href="favicon.png">

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <link rel="stylesheet" type="text/css" href="fonts/font-awesome-4.7.0/css/font-awesome.min.css">
    <!--===============================================================================================-->
    <link rel="stylesheet" type="text/css" href="vendor/animate/animate.css">
    <!--===============================================================================================-->
    <link rel="stylesheet" type="text/css" href="vendor/select2/select2.min.css">
    <!--===============================================================================================-->
    <link rel="stylesheet" type="text/css" href="vendor/perfect-scrollbar/perfect-scrollbar.css">
    <!--===============================================================================================-->
    <link rel="stylesheet" type="text/css" href="css/util.css">
    <link rel="stylesheet" type="text/css" href="css/main.css">

    <style type="text/css">
        .navbar-text > a {
            color: inherit;
            text-decoration: none;
        }

        .white_bg {
            background-color: #eef7fa;
            padding: 3px;
        }

        .line2 {
            margin: 5px 0;
            height: 2px;
            background: repeating-linear-gradient(to right, black 0, black 10px, transparent 10px, transparent 12px)
            /*10px red then 2px transparent -> repeat this!*/
        }

        .bordered, .hover2, xximg:hover {
            border-color: #AAAAAA;
            border-style: solid;
            border-width: 1px;
            border-collapse: separate /* otherwise does not work in IE inside tables */;
        }

        .hover2 {
            -webkit-box-shadow: 2px 2px 2px rgba(, , 120, 0.6);
            -moz-box-shadow: 2px 2px 2px rgba(, , 120, 0.6);
            -o-box-shadow: 2px 2px 2px rgba(, , 120, 0.6);
            box-shadow: 0px 0px 10px rgba(, , 120, 0.6);
        }

        figure figcaption {
            text-align: center;
            margin: 10px;
        }

        figure {
            display: inline-block;
            margin: 0px;
        }

        figure img {
            vertical-align: top;
            border: 1px solid #ddd;
            border-radius: 0px;
            padding: 0px;
        }

        figure img:hover {
            opacity: 0.7;
            filter: alpha(opacity=70);
            -webkit-box-shadow: -2px 4px 10px 0px rgba(0, 0, 0, 1);
            -moz-box-shadow: -2px 4px 10px 0px rgba(0, 0, 0, 1);
            box-shadow: -2px 4px 10px 0px rgba(0, 0, 0, 1);
            -webkit-transition: all .2s ease-in-out;
            transition: all .2s ease-in-out;

        }
    </style>
</head>

<body id="page-top">

<!-- Navigation -->
<nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top" id="mainNav">
    <div class="container">
        <div class="navbar-header">
            <a class="navbar-brand js-scroll-trigger" href="#">
                SSNLP 2023
            </a>
        </div>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive"
                aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
            <ul class="navbar-nav ml-auto">
                <li class="nav-item">
                    <a class="nav-link js-scroll-trigger" href="#overview">Overview</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link js-scroll-trigger" href="#programme">Programme</a>
                </li>
<!-- Speakers -->
                <li class="nav-item">
                    <a class="nav-link js-scroll-trigger" href="#organizers">Organizers</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link js-scroll-trigger" href="#partners">Partners</a>
                </li>
<!-- Partners, Photos -->
                <li class="nav-item">
                    <a class="nav-link js-scroll-trigger" href="#location">Location</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link js-scroll-trigger" href="#past-ssnlp">Past SSNLP</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link js-scroll-trigger" href="#contact">Contact</a>
                </li>
            </ul>
        </div>
    </div>
</nav>

<header class="bg-primary text-white">
    <div class="container text-center">
        <h1 style="font-size: 60px;font-weight: bold;color: rebeccapurple;">SSNLP 2023</h1>
        <h2 style="font-size: 35px">The 2023 Singapore Symposium on Natural Language Processing</h2>
    </div>
</header>

<section id="overview" class="bg-light">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <h2>Welcome!</h2>
                <p style="text-align: justify;">We are pleased to announce that <b>the Singapore Symposium on Natural Language Processing (SSNLP 2023)</b> will be held on <b>Monday, December 4</b> (full day). This is an annual Singapore-based pre-conference practice workshop for both local students, practitioners and faculty working in Natural Language Processing to network. It has been successfully held in 2018, 2019, 2020, and 2022, becoming an increasingly popular and impactful event.
              <!--    [ <a href="https://www.comp.nus.edu.sg/maps/photos#com1">Map</A> ]
                  [ <a href="https://www.comp.nus.edu.sg/images/resources/content/mapsvenues/COM1_L2.jpg">Floorplan</A> ]-->
                </p>

	    	<p style="text-align: justify;">We are further excited about the unique opportunity presented to Singapore on 6-10 December as the EMNLP 2023, a premier Computational Linguistics and NLP conference, is being held in Singapore. Leveraging the attendance of many reputed academicians, we’re looking forward to hosting them as a part of SSNLP – and, further, taking the opportunity to invite them to the School of Computing of National University of Singapore (NUS) to engage with us.
		</p>

                <p style="text-align: justify;">SSNLP is a free onsite event, open to the public, but <b>requires registration</b>. The venue will be held at <b>the Shaw Foundation Alumni House Auditorium, NUS (11 Kent Ridge Dr, Singapore 119244, [<a href="https://www.google.com/maps/place/Shaw+Foundation+Alumni+House/@1.2932317,103.7708068,17z/data=!3m2!4b1!5s0x31da1aff3ee4a48f:0x732a458e6add7ca5!4m6!3m5!1s0x31da1aff3f1cf5b1:0x7ae21f4141402cfd!8m2!3d1.2932263!4d103.7733817!16s%2Fg%2F11bx1h3zc_?entry=ttu">Map</a>], [<a href="images/Shaw-1.jpg">Outdoor photo</a>], [<a href="images/Shaw-2.jpg">Indoor photo</a>])</b>. Make early bird registration to secure seats:</p>
                <center>
                  <p>
                    <a href="#" target="_blank" class="btn btn-primary">Registration</a>
                  </p>
                </center>

<!--                 <p>Due to fire code restrictions, our venues cannot accommodate additional onsite registrations.  However, we have plenty of capacity for virtual attendance.  Feel free to request the link for the virtual registration below.
                </p>
                <center>
                  <p>
                    <a href="mailto:haofei37@nus.edu.sg?subject=SSNLP 2023 Virtual Registration&body=Hi, I'd like to receive the Zoom link for the upcoming SSNLP event on 5 December 2023.  Can you send it to me?  Thank you!" target="_blank" class="btn btn-primary">Register to get the Virtual Attendance Zoom links</a>
                  </p>
                </center> -->

                <h5>Latest news</h5>
                <br>
                   <p><span class="white_bg"><strong>December 4, 2023</strong> — The date is confirmed. Please registrate now!</span></p>
                <p>

            </div>
        </div>
    </div>
</section>

<section id="programme" class="bg-light">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <h2>Programme</h2>

		<p style="text-align: justify;">We've planed to host Oral and Post sessions for paper presentations, and also have invited Keynote Speakers.</p>
	    	
                <div class="container-table100">
                    <div class="wrap-table100">

                        <div class="table100 ver5 m-b-10">
                            <table data-vertable="ver5">
                                <thead>
                                <tr class="row100 head">
                                    <th class="column100 column1" data-column="column1"><strong>October 31,
                                        2019</strong></th>
                                    <th class="column100 column2" data-column="column2"></th>
                                </tr>
                                </thead>
                                <tbody>

                                <tr class="row100">
                                    <td class="column100 column1" data-column="column1">08:00 - 08:15</td>
                                    <td class="column100 column2" data-column="column2"><strong>Welcome and Opening
                                        Remarks</strong></td>
                                </tr>

                                <tr class="row100">
                                    <td class="column100 column1" data-column="column1">08:15 - 09:15</td>
                                    <td class="column100 column2" data-column="column2">
                                        <a href="files/#">
                                            <strong>Paper session 1</strong>
                                        </a>
<!--                                         <br>
                                        <em>speaker:</em> &nbsp; <font color="red">Heng Ji</font> &nbsp; :: &nbsp; <em>chaired
                                        by:</em> &nbsp; Nancy Chen -->
                                    </td>
                                </tr>

<!--                                 <tr class="row100">
                                    <td class="column100 column1" data-column="column1">09:30 - 10:30</td>
                                    <td class="column100 column2" data-column="column2"><strong>Tea Break</strong></td>
                                </tr> -->

                                <tr class="row100">
                                    <td class="column100 column1" data-column="column1">09:30 - 10:30</td>
                                    <td class="column100 column2" data-column="column2">
                                        <a href="files/#">
                                            <strong>News: Keynote 1 (20 mins) and 2 (20 mins) on related topic with joint Q&A (20 mins) ()</strong>
                                        </a>
                                        <br> <em>speaker:</em> &nbsp; <font color="red">Preslav and Farah</font> &nbsp;  &nbsp;
<!--                                          <em>chaired by:</em> &nbsp; Francis Bond -->
                                    </td>
                                </tr>

                                <tr class="row100">
                                    <td class="column100 column1" data-column="column1">10:30-11:30</td>
                                    <td class="column100 column2" data-column="column2">
                                        <a href="files/#">
                                            <strong>Paper session 2</strong>
                                        </a>
<!-- 					    <br> <em>speaker:</em> &nbsp; <font color="red">Rada
                                        Mihalcea</font> &nbsp; :: &nbsp; <em>chaired by:</em> &nbsp; Francis Bond -->
                                    </td>
                                </tr>

                                <tr class="row100">
                                    <td class="column100 column1" data-column="column1">11:30 - 12:30</td>
                                    <td class="column100 column2" data-column="column2">
                                        <a href="files/#">
                                            <strong>Architectures: Keynote 3 and 4, same format</strong>
                                        </a>
                                        <br> <em>speaker:</em> &nbsp; <font color="red">Vivian and Tanya</font> &nbsp; &nbsp; 
<!-- 					    <em>chaired by:</em> &nbsp; Francis Bond -->
                                    </td>
                                </tr>

                                <tr class="row100">
                                    <td class="column100 column1" data-column="column1">12:30 - 13:00</td>
                                    <td class="column100 column2" data-column="column2">
					    <a href="files/ed_hovy_ssnlp.pdf">
						    <strong>Poster lightning talks</strong></td>
                                        </a>
				     </td>
                                </tr>

                                <tr class="row100">
                                    <td class="column100 column1" data-column="column1">13:00 - 14:15</td>
                                    <td class="column100 column2" data-column="column2">                                        
                                            <strong>Poster session and lunch</strong>
<!--                                         <br> <em>speaker:</em> &nbsp; <font color="red">Eduard Hovy</font> &nbsp; ::
                                        &nbsp; <em>chaired by:</em> &nbsp; Li Haizhou -->
                                    </td>
                                </tr>

                                <tr class="row100">
                                    <td class="column100 column1" data-column="column1">14:15 - 15:15</td>
                                    <td class="column100 column2" data-column="column2">
                                        <a href="files/#">
                                            <strong>Paper session 3</strong>
                                        </a>					    
                                    </td>
                                </tr>


                                <tr class="row100">
                                    <td class="column100 column1" data-column="column1">15:15 - 16:15</td>
                                    <td class="column100 column2" data-column="column2">
                                        <a href="files/#">
                                            <strong>Intents: Keynote 5 and 6, same format</strong>
                                        </a>
                                        <br> <em>speaker:</em> &nbsp; <font color="red">Diyi and Joao</font>
<!--                                         &nbsp; :: &nbsp; <em>chaired by:</em> &nbsp; Li Haizhou -->
				     </td>
                                </tr>


                                <tr class="row100">
                                    <td class="column100 column1" data-column="column1">16:30 - 18:00</td>
                                    <td class="column100 column2" data-column="column2">

                                        <a href="files/#">
                                            <strong>Industry session & Career Q&A</strong>
                                        </a>
                                        <br> <em>speaker:</em> &nbsp; <font color="red">Daniel, Huda, Alessandro, Lidong</font>
				     </td>
                                </tr>

                                <tr class="row100">
                                    <td class="column100 column1" data-column="column1">18:00 - 18:30</td>
                                    <td class="column100 column2" data-column="column2"><strong>Townhall</strong>
                                    </td>
                                </tr>

                                <!--                                 <tr class="row100">
                                                                    <td class="column100 column1" data-column="column1">17:30 - 18:00</td>
                                                                    <td class="column100 column2" data-column="column2">
                                                                    </td>
                                                                </tr> -->

                                <tr class="row100">
                                    <td class="column100 column1" data-column="column1"></td>
                                    <td class="column100 column2" data-column="column2"></td>
                                </tr>

                                </tbody>

                            </table>
                        </div>
                    </div>
                </div>
		    
		    
<!--                <p>
                  Oral sessions are for 12 minutes plus 3 minutes for immediate questions.  There will be ample time after a session to engage in the breaks directly after the session.  Session chairs should record each session and check with the speakers if they want their post-recorded session made public.
                  Questions will be solicited via crowdsourcing via Padlets.
                <div class="container-table">
                    <div class="wrap-table">

                        <div class="table ver5 m-b-10">
                            <table data-vertable="ver5">
                                <thead>
                                <tr class="row100 head">
                                    <th class="column100" data-column="column1"><strong>5 December,
                                        2023</strong></th>
                                    <th class="column100" data-column="column2">Seminar Room 2 (SR2)</th>
                                    <th class="column100" data-column="column3">Seminar Room 3 (SR3)</th>
                                </tr>
                                </thead>
                                <tbody>

                                <tr class="row100">
                                    <td class="column100" data-column="column1">09:00—09:45</td>
                                    <td class="column100" data-column="column2"><strong>Session 1A</strong><br/>
                                      <strong>Information Extraction</strong><br/>(<i>Session Chair: Yanxia Qin</i>)
                                      <p style="text-align:left; font-size:small">
                                        [1] Yubo Ma, Zehao Wang, Yixin Cao, Mukai Li, Meiqi Chen, Kun Wang, Jing Shao. <i>Prompt for Extraction? PAIE: Prompting Argument Interaction for Event Argument Extraction.</i><BR/>
                                        [2] Qingyu Tan, Ruidan He, Lidong Bing, Hwee Tou Ng. <i>Document-Level Relation Extraction with Adaptive Focal Loss and Knowledge Distillation.</i><BR/>
                                        [3] Timothy Liu and De Wen Soh. <i>Towards Better Characterization of Paraphrases.</i>
                                      </p>
                                    </td>
                                    <td class="column100" data-column="column3"><strong>Session 1B</strong><br/>
                                      <strong>NLP Applications</strong><br/>(<i>Session Chair: Prathyusha Jwalapuram</i>)
                                      <p style="text-align:left; font-size:small">
                                        [1] Hai Ye, Hwee Tou Ng, Wenjuan Han. <i>On the Robustness of Question Rewriting Systems to Questions of Varying Hardness.</i><BR/>
                                        [2] Mathieu Ravaut, Shafiq Joty, Nancy F. Chen. <i>SummaReranker: A Multi-Task Mixture-of-Experts Reranking Framework for Abstractive Summarization.</i><BR/>
                                        [3] Xiaobing Sun, Wei Lu. <i>Implicit N-grams Induced by Recurrence.</i>
                                      </p>
                                    </td>
                                </tr>

                                <tr class="row100">
                                    <td class="column100" data-column="column1">09:45—10:15</td>
                                    <td colspan="2" class="column100" data-column="column2"><strong>Break 1</strong></td>
                                </tr>

                                <tr class="row100">
                                    <td class="column100" data-column="column1">10:15—11:00</td>
                                    <td class="column100" data-column="column2"><strong>Session 2A</strong><br/>
                                      <strong>Syntax and Discourse</strong><br/>(<i>Session Chair: Qingyu Tan</i>)
                                      <p style="text-align:left; font-size:small">
                                        [1] Muhammad Reza Qorib, Seung-Hoon Na, Hwee Tou Ng. <i>Frustratingly Easy System Combination for Grammatical Error Correction.</i> <BR/>
                                        [2] Liying Cheng, Lidong Bing, Ruidan He, Qian Yu, Yan Zhang, Luo Si. <i>IAM: A Comprehensive and Large-Scale Dataset for Integrated Argument Mining Tasks.</i><BR/>
                                        [3] Prathyusha Jwalapuram, Shafiq Joty, Xiang Lin. <i>Rethinking Self-Supervision Objectives for Generalizable Coherence Modeling.</i>
                                      </p>
                                    </td>
                                    <td class="column100" data-column="column-3"><strong>Session 2B</strong><BR/>
                                      <strong>Multimodality</strong><br/>(<i>Session Chair: Liangming Pan</i>)
                                      <p style="text-align:left; font-size:small">
                                        [1] Allan Jie, Jierui Li, Wei Lu. <i>Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.</i><BR/>
                                        [2] Shankar Kantharaj, Rixie Leong, Xiang Lin, Ahmed Masry, Megh Thakkar, Enamul Hoque, Shafiq Joty. <i>Chart2Text: A large-scale benchmark for chart summarization. </i><BR/>
                                        [3] Ahmed Masry, Do Xuan Long, Jia Qing Tan, Shafiq Joty, Enamul Hoque. <i>ChartQA: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning.</i>
                                      </p>
                                    </td>
                                </tr>

                                <tr class="row100">
                                    <td class="column100" data-column="column1">11:00—13:00</td>
                                    <td colspan="2" class="column100" data-column="column2"><strong>Lunch (courtesy ByteDance)</strong></td>
                                </tr>

                                <tr class="row100">
                                    <td class="column100" data-column="column1">12:00—13:00</td>
                                    <td colspan="2" class="column100" data-column="column2"><strong>Poster Session 1</strong></td>
                                </tr>

                                <tr class="row100">
                                    <td class="column100" data-column="column1">13:00—13:45</td>
                                    <td class="column100" data-column="column2"><strong>Session 3A</strong><br/>
                                      <strong>Dialog</strong><br/>(<i>Session Chair: Min-Yen Kan</i>)
                                      <p style="text-align:left; font-size:small">
                                        [1] Bosheng Ding, Junjie Hu, Lidong Bing, Mahani Aljunied, Shafiq Joty, Luo Si, Chunyan Miao. <i>GlobalWoZ: Globalizing MultiWoZ to Develop Multilingual Task-Oriented Dialogue Systems. </i><BR/>
                                        [2] Hung Le, Nancy F. Chen, Steven Hoi. <i>Multimodal Dialogue State Tracking.</i> <BR/>
                                        [3] Deepanway Ghosal, Siqi Shen, Navonil Majumder, Rada Mihalcea, Soujanya Poria. <i>CICERO: A Dataset for Contextualized Commonsense Inference in Dialogues.</i>
                                      </p>
                                    </td>
                                    <td class="column100" data-column="column3"><strong>Session 3B</strong><br/>
                                      <strong>Domain Adaptation / Few Shot Learning</strong><br/>(<i>Session Chair: Liying Cheng</i>)
                                      <p style="text-align:left; font-size:small">
                                        [1] Lulu Zhao, Fujia Zheng, Weihao Zeng, Keqing He, Weiran Xu, Huixing Jiang, Wei Wu, Yanan Wu. <i>Domain-Oriented Prefix-Tuning: Towards Efficient and Generalizable Fine-tuning for Zero-Shot Dialogue Summarization.</i> <BR/>
                                        [2] Chengwei Qin, Shafiq Joty. <i>Continual Few-shot Relation Learning via Embedding Space Regularization and Data Augmentation.</i><BR/>
                                        [3] Chia Yew Ken, Lidong Bing, Soujanya Poria, Luo Si. <i>RelationPrompt: Leveraging Prompts to Generate Synthetic Data for Zero-Shot Relation Triplet Extraction.</i>
                                        </p>
                                    </td>
                                </tr>

                                <tr class="row100">
                                    <td class="column100" data-column="column-1">13:45—14:15</td>
                                    <td colspan="2" class="column100" data-column="column-1"><strong>Break 2</strong></td>
                                </tr>

                                <tr class="row100">
                                    <td class="column100" data-column="column-1">14:15—15:00</td>
                                    <td class="column100" data-column="column-2"><strong>Session 4A</strong><BR/>
                                      <strong>Language Models</strong><br/>(<i>Session Chair: Bosheng Ding</i>)
                                      <p style="text-align:left; font-size:small">
                                        [1] Minghuan Tan, Yong Dai, Duyu Tang, Zhangyin Feng, Guoping Huang, Jing Jiang, Jiwei Li, Shuming Shi. <i>Exploring and Adapting Chinese GPT to Pinyin Input Method.</i><BR/>
                                        [2] Xiaosen Zheng, Jing Jiang. <i>An Empirical Study of Memorization in NLP.</i><BR/>
                                        [3] Yunxiang Zhang, Liangming Pan, Samson Tan, Min-Yen Kan. <i>Interpreting the Robustness of Neural NLP Models to Textual Perturbations.</i>
                                      </p>
                                    </td>
                                    <td class="column100" data-column="column3"><strong>Session 4B</strong><br/>
                                      <strong>Generation</strong><br/>(<i>Session Chair: Yisong Miao</i>)
                                      <p style="text-align:left; font-size:small">
                                        [1] Abhinav Ramesh Kashyap, Devamanyu Hazarika, Min-Yen Kan, Roger Zimmermann, Soujanya Poria. <i>So Different Yet So Alike! Constrained Unsupervised Text Style Transfer.</i><BR/>
                                        [2] Chenhui Shen, Liying Cheng, Ran Zhou, Lidong Bing, Yang You, Luo Si. <i>MReD: A Meta-Review Dataset for Structure-Controllable Text Generation.</i><BR/>
                                        [3] Zhengyuan Liu, Nancy F. Chen. <i>Learning from Bootstrapping and Stepwise Reinforcement Reward: A Semi-Supervised Framework for Text Style Transfer.</i>
                                      </p>
                                    </td>
                                </tr>

                                <tr class="row100">
                                    <td class="column100" data-column="column-1">15:00—16:00</td>
                                    <td colspan="2" class="column100" data-column="column-2"><strong>Poster Session 2</strong>
                                </tr>

                            </table>
                        </div>

                        <h3>Posters</h3>

                        <p>Posters will be shown in the foyer of Seminar Room (SR2).  Posters are short, workshop, work-in-progress papers or last minute additions to our programme.  Poster boards can accommodate A1 sized posters, in either portrait or landscape.

                        <div class="table ver5 m-b-10">
                            <table data-vertable="ver5">
                                <tbody>

                                <tr class="row100">
                                    <td class="column100" data-column="column1">
                                      <p style="text-align:left; font-size:small">
                                        [1] Ruixi Lin, Hwee Tou Ng. <i>Does BERT Know that the IS-A Relation is Transitive? </i><BR/>
                                        [2] Saurabh Jain, Yisong Miao, Min-Yen Kan. <i>Comparative Snippet Generation.</i><BR/>
                                        [3] Sicheng Yu, Qianru Sun, Hao Zhang, Jing Jiang. <i>Translate-Train Embracing Translationese Artifacts.</i> <BR/>
                                        [4] Ibrahim Taha Aksu, Zhengyuan Liu, Min-Yen Kan and Nancy F. Chen. <i>N-Shot Learning for Augmenting Task-Oriented Dialogue State Tracking.</i><BR/>
                                        [5] Hung Le, Nancy F. Chen, Steven Hoi. <i>VGNMN: Video-grounded Neural Module Networks for Video-Grounded Dialogue Systems.</i><BR/>
                                        [6] Moxin Li, Fuli Feng, Hanwang Zhang, Xiangnan He, Fengbin Zhu, Tat-Seng Chua. <i>Learning to Imagine: Integrating Counterfactual Thinking in Neural Discrete Reasoning.</i><BR/>
                                        [7] Fengzhu Zeng, Wei Gao. <i>Early Rumor Detection Using Neural Hawkes Process with a New Benchmark Dataset.</i>
                                        </p>
                                    </td>
                                </tr>
                            </table>
                        </div>

                    </div>
                </div>-->
            </div>
        </div>
    </div>
</section>



<section id="speakers" class="bg-light">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <h3>Keynote Speakers TBD</h3>
                <p>
                    The following speakers are invited to give keynotes at SSNLP 2023. Please click the profile image to view the detailed
                    content of the talk.
                </p>



                <div class="accordion" id="accordion">
                    <div class="table-responsive">
                        <table class="table">
                            <tbody>
                            <tr align="center">
                                <td>
                                    <a href="#rada" data-toggle="collapse">
                                        <figure>
                                            <img src="images/rada.jpg" class="hover2" width="150" height="192">
                                            <figcaption><h5>Rada Mihalcea</h5></figcaption>
                                        </figure>
                                    </a>
                                </td>
                                <td>
                                    <a href="#edhovy" data-toggle="collapse">
                                        <figure>
                                            <img src="images/ed.png" class="hover2" align="center" width="150"
                                                 height="192">
                                            <figcaption>
                                                <h5>Eduard Hovy</h5>
                                            </figcaption>
                                        </figure>
                                    </a>
                                </td>
                                <td>
                                    <a href="#hengji" data-toggle="collapse">
                                        <figure>
                                            <img src="images/hengji.png" class="hover2" width="150" height="192">
                                            <figcaption><h5>Heng Ji</h5></figcaption>
                                        </figure>
                                    </a>
                                </td>

                            </tr>
                            </tbody>
                        </table>
                    </div>


                    <div id="rada" class="collapse" data-parent="#accordion">
                        <strong>Title: </strong> The Ups and Downs of Word Embeddings
                        <br>
                        <strong>Speaker: </strong><a href="https://web.eecs.umich.edu/~mihalcea/">Rada Mihalcea</a>
                        <br>
                        <br>
                        <strong> Abstract: </strong> Words are the central units of the languages we all speak. In a
                        similar way, word representations are the core units of the algorithms that we build to
                        automatically process language, and they form the foundation for many applications of natural
                        language processing, ranging from question answering systems, to chat bots, search engines, or
                        systems for machine translation. In this talk, I will take a deep dive into word embeddings, and
                        address two aspects of word embeddings. First, I will take a close look at their stability, and
                        show that even relatively high frequency words are often unstable. I will provide empirical
                        evidence for how various factors contribute to the stability of word embeddings, and analyze the
                        effects of stability on downstream tasks. Second, I will explore the relation between words and
                        people and show how we can develop cross-cultural word representations to identify words with
                        cultural influence, and also how we can effectively use information about the people behind the
                        words to build better word representations. This is joint work with Laura Burdick, Aparna
                        Garimella, Carmen Banea.

                        <br>
                        <br>
                        <strong>Bio:</strong> Rada Mihalcea is a Professor of Computer Science and Engineering at the
                        University of Michigan and the Director of the Michigan Artificial Intelligence Lab. Her
                        research interests are in computational linguistics, with a focus on lexical semantics,
                        multilingual natural language processing, and computational social sciences. She serves or has
                        served on the editorial boards of the Journals of Computational Linguistics, Language Resources
                        and Evaluations, Natural Language Engineering, Journal of Artificial Intelligence Research, IEEE
                        Transactions on Affective Computing, and Transactions of the Association for Computational
                        Linguistics. She was a program co-chair for EMNLP 2009 and ACL 2011, and a general chair for
                        NAACL 2015 and *SEM 2019. She currently serves as the ACL Vice-President Elect. She is the
                        recipient of a National Science Foundation CAREER award (2008) and a Presidential Early Career
                        Award for Scientists and Engineers awarded by President Obama (2009). In 2013, she was made an
                        honorary citizen of her hometown of Cluj-Napoca, Romania.
                        <br>
                        <br>
                    </div>

                    <div id="edhovy" class="collapse" data-parent="#accordion">
                        <strong>Title: </strong>From Simple to Complex QA
                        <br>
                        <strong>Speaker: </strong><a href="https://www.cs.cmu.edu/~hovy">Eduard Hovy</a>
                        <br>
                        <br>
                        <strong> Abstract: </strong>In modern automated QA research, what differentiates simple/shallow
                        from complex/deep QA? Early QA research developed pattern-learning and -matching techniques to
                        identify the appropriate factoid answer(s), and this approach has been taken a step further
                        recently by recent neural architectures that learn and apply more-flexible generalized
                        word/type-sequence ‘patterns’. However, many QA tasks require some sort of intermediate
                        reasoning or other inference procedures more complex than generalization over pattern-anchored
                        words and phrases. In one approach, people focus on the automated construction of small access
                        functions to locate the answer in structured resources like tables or databases. But much (or
                        most) knowledge is not structured, and what to do in this case is unclear. Most current ‘deep’
                        QA approaches take a one-size-fits-all approach in which they essentially hope that a
                        multi-layer neural architecture will somehow learn to encode inference steps automatically. The
                        main problem facing this line of research is the difficulty in defining exactly what kinds of
                        reasoning are relevant, and what knowledge resources are required to support them. If all
                        relevant knowledge is apparent on the surface of the question material, then shallow
                        pattern-matching techniques (perhaps involving combinations of patterns) can surely be developed
                        using simple/shallow methods. But if not, then (at least some of) the relevant knowledge is
                        either internal to the QA system or resides in some additional, external resource (like the
                        web), which makes the design and construction of general comprehensive datasets and evaluations
                        very difficult. (In fact, the same problem faces all in-depth semantic analysis research topics,
                        including entailment, machine reading, semantic information extraction, and more.) How should
                        the Complex-QA community respond to this conundrum? In this talk I outline the problem, define
                        four levels of QA, and propose a general direction for future research.
                        <br>
                        <br>
                        <strong>Bio:</strong> Eduard Hovy is a research full professor at the Language Technologies
                        Institute in the
                        School of Computer Science at Carnegie Mellon University. He also holds adjunct
                        professorships in CMU’s Machine Learning Department and at USC (Los Angeles) and BUPT
                        (China). Dr. Hovy completed a Ph.D. in Computer Science (Artificial Intelligence) at Yale
                        University in 1987, and was awarded honorary doctorates from the National Distance
                        Education University (UNED) in Madrid in 2013 and the University of Antwerp in 2015. He
                        is one of the initial 17 Fellows of the Association for Computational Linguistics (ACL) and
                        also a Fellow of the Association for the Advancement of Artificial Intelligence (AAAI). Dr.
                        Hovy’s research focuses on computational semantics of language, and addresses various
                        areas in Natural Language Processing and Data Analytics, including in-depth machine
                        reading of text, information extraction, automated text summarization, question answering,
                        the semi-automated construction of large lexicons and ontologies, and machine translation.
                        In early 2019 his Google h-index was 77, with over 27,000 citations. Dr. Hovy is the author
                        or co-editor of six books and over 400 technical articles and is a popular invited speaker.
                        From 2003 to 2015 he was co-Director of Research for the Department of Homeland
                        Security’s Center of Excellence for Command, Control, and Interoperability Data Analytics, a
                        distributed cooperation of 17 universities. In 2001 Dr. Hovy served as President of the
                        international Association of Computational Linguistics (ACL), in 2001–03 as President of
                        the International Association of Machine Translation (IAMT), and in 2010–11 as President
                        of the Digital Government Society (DGS). Dr. Hovy regularly co-teaches Ph.D.-level courses
                        and has served on Advisory and Review Boards for both research institutes and funding
                        organizations in Germany, Italy, Netherlands, Ireland, Singapore, and the USA.
                        <br>
                        <br>
                    </div>

                    <div id="hengji" class="collapse" data-parent="#accordion">
                        <strong>Title: </strong>Cross-lingual Cross-media Relation and Event Structure Transfer
                        <br>
                        <strong>Speaker: </strong><a href="http://nlp.cs.rpi.edu/hengji.html">Heng Ji</a>
                        <br>
                        <br>
                        <strong> Abstract: </strong>
                        The identification of complex semantic graph structures such as events and entity relations from
                        unstructured texts, already a challenging Information Extraction task, is doubly difficult to
                        extract from sources written in under-resourced and under-annotated languages. We investigate
                        the suitability of cross-lingual cross-media graph structure transfer techniques for these
                        tasks. Previous efforts on cross-lingual transfer are limited to sequence level. In contrast, we
                        observe that relational facts are typically expressed by identifiable structured graph patterns
                        across multiple languages and data modalities. We exploit relation- and event-relevant
                        language-universal and modality-universal features, leveraging both symbolic (including
                        part-of-speech and dependency path) and distributional (including type representation and
                        contextualized representation) information. We then represent all entity mentions, event
                        triggers, and contexts into this complex and structured multilingual common space, using graph
                        convolutional networks. In this way all the sentences from multiple languages, along with visual
                        objects from images are represented as one shared unified graph representation. We then train a
                        relation or event extractor from source language annotations and apply it to the target language
                        and images. Extensive experiments on cross-lingual and cross-media relation and event transfer
                        demonstrate that our approach achieves performance comparable to state-of-the-art supervised
                        models trained on up to 3,000 manually annotated mentions, and dramatically outperforms methods
                        learned from flat representation. I will show a preliminary demo on applying the resultant event
                        knowledge base for automatic history book generation.
                        <br>
                        <br>
                        <strong>Bio:</strong>
                        Heng Ji is a professor at Computer Science Department of University of Illinois at
                        Urbana-Champaign. She received her B.A. and M. A. in Computational Linguistics from Tsinghua
                        University, and her M.S. and Ph.D. in Computer Science from New York University. Her research
                        interests focus on Natural Language Processing, especially on Information Extraction and
                        Knowledge Base Population. She is selected as "Young Scientist" and a member of the Global
                        Future Council on the Future of Computing by the World Economic Forum in 2016 and 2017. The
                        awards she received include "AI's 10 to Watch" Award by IEEE Intelligent Systems in 2013 and NSF
                        CAREER award in 2009. She has coordinated the NIST TAC Knowledge Base Population task since
                        2010. She is the associate editor for IEEE/ACM Transaction on Audio, Speech, and Language
                        Processing, and served as the Program Committee Co-Chair of many conferences including
                        NAACL-HLT2018.
                        <br>
                        <br>
                    </div>


                    <div class="table-responsive">
                        <table class="table">
                            <tbody>
                            <tr align="center">
                                <td>
                                    <a href="#william" data-toggle="collapse">
                                        <figure>
                                            <img src="https://sites.cs.ucsb.edu/~william/profile18.jpg" class="hover2"
                                                 width="150" height="192">
                                            <figcaption><h5>William Wang</h5></figcaption>
                                        </figure>
                                    </a>
                                </td>
                                <td>
                                    <a href="#john" data-toggle="collapse">
                                        <figure>
                                            <img src="http://john.mccr.ae/me.jpg" class="hover2"
                                                 width="150" height="192">
                                            <figcaption><h5>John McCrae</h5></figcaption>
                                        </figure>
                                    </a>
                                </td>
                                <td>
                                    <a href="#preslav" data-toggle="collapse">
                                        <figure>
                                            <img src="images/preslav.png" class="hover2" width="150" height="192">
                                            <figcaption><h5>Preslav Nakov</h5></figcaption>
                                        </figure>
                                    </a>
                                </td>
                                <!--                                 <td>
                                                                    <a href="#pascale" data-toggle="collapse">
                                                                        <figure>
                                                                            <img src="images/pascale.jpeg" class="hover2"
                                                                                 width="150" height="192">
                                                                            <figcaption><h5>Pascale Fung</h5></figcaption>
                                                                        </figure>
                                                                    </a>
                                                                </td> -->
                            </tr>
                            </tbody>
                        </table>
                    </div>

                    <div id="william" class="collapse" data-parent="#accordion">
                        <strong>Title: </strong> Self-Supervised Natural Language Processing
                        <br>
                        <strong>Speaker: </strong><a href="https://sites.cs.ucsb.edu/~william/">William Wang</a>
                        <br>
                        <br>
                        <strong> Abstract:</strong> With the vast amount of language data available in digital form, now
                        is a good opportunity to move beyond traditional supervised learning methods. The core research
                        question that I will address in this talk is the following: What is self-supervised learning?
                        What is the success story behind BERT and XLNet? How can we design self-supervised deep learning
                        methods to operate over rich language and knowledge representations? In this talk, I will
                        describe some examples of my work in advancing the state-of-the-arts in methods of
                        self-supervised learning for NLP, including: 1) AREL, a self-adaptive inverse reinforcement
                        learning agent for visual storytelling; and 2) Self-supervised learning that goes beyond
                        surface-level representation learning. I will conclude this talk by describing my other research
                        interests in the interdisciplinary field of AI/ML/NLP/Vision.
                        <br>
                        <br>
                        <strong>Bio:</strong> William Wang is an Assistant Professor in the Department of Computer
                        Science at the University of California, Santa Barbara. He is the Director of UCSB's Responsible
                        Machine Learning Center. He received his PhD from School of Computer Science, Carnegie Mellon
                        University in 2016. He has broad interests in machine learning approaches to data science,
                        including natural language processing, statistical relational learning, information extraction,
                        computational social science, dialogue, and vision. He directs UCSB’s NLP Group
                        (nlp.cs.ucsb.edu): in two years, UCSB advanced in the NLP area from an undefined ranking
                        position to top 3 in 2018 according to CSRankings.org. He has published more than 80 papers at
                        leading NLP/AI/ML conferences and journals, and received best paper awards (or nominations) at
                        ASRU 2013, CIKM 2013, EMNLP 2015, and CVPR 2019, a DARPA Young Faculty Award (Class of 2018), a
                        Google Faculty Research Award (2018), two IBM Faculty Awards in 2017 and 2018, a Facebook
                        Research Award in 2018, an Adobe Research Award in 2018, and the Richard King Mellon
                        Presidential Fellowship in 2011. He frequently serves as an Area Chair for NAACL, ACL, EMNLP,
                        and AAAI. He is an alumnus of Columbia University, Yahoo! Labs, Microsoft Research Redmond, and
                        University of Southern California. In addition to research, William enjoys writing scientific
                        articles that influence the broader online community: his microblog Weibo has 116,000+ followers
                        and more than 2,000,000 views each month. His work and opinions frequently appear at major
                        international media outlets such as Wired, VICE, Fast Company, NASDAQ, Scientific American, The
                        Next Web, The Brookings Institution, Law.com, and Mental Floss.
                        <br>
                        <br>
                    </div>
                    <div id="john" class="collapse" data-parent="#accordion">
                        <strong>Title: </strong> Linking Languages Across Space and Time
                        <br>
                        <strong>Speaker: </strong><a href="http://john.mccr.ae/">John McCrae</a>
                        <br>
                        <br>
                        <strong> Abstract:</strong> NLP is moving increasingly from working on only a few well-resourced
                        languages to meet the challenges of a globalising world connected through the internet. As such,
                        connecting all these languages is of increasing importance and new technologies to link across
                        language boundaries are necessary. I will present some results from the ELEXIS (European
                        Lexicographic Infrastructure) project, which aims to connect lexicographers with NLP researchers
                        across Europe and link their dictionaries through a new dictionary matrix. Secondly, I will talk
                        about the Cardamom project, which aims to extend NLP technology to minority languages and also
                        historical languages by exploiting information from well-resourced closely-related languages.
                        <br>
                        <br>
                        <strong>Bio:</strong>
                        John McCrae is a lecturer above-the-bar at the Data Science Institute and Insight Centre for
                        Data Analytics at the National University of Ireland Galway and the leader of the Unit for
                        Linguistic Data. He is the coordinator of the Prêt-à-LLOD project and work package leader in the
                        ELEXIS infrastructure. His research interests span
                        Machine learning methods for NLP,
                        Digital Humanities,
                        Machine translation and multilingualism, etc.
                        He obtained his PhD from the National Institute of Informatics in Tokyo under the supervision of
                        Nigel Collier and until 2015 he was a post-doctoral researcher at the University of Bielefeld in
                        Bielefeld, Germany in Prof. Philipp Cimiano's group, AG Semantic Computing.
                        <br>
                        <br>
                    </div>
                    <div id="preslav" class="collapse" data-parent="#accordion">
                        <strong>Title: </strong>Detecting the "Fake News" Before They Were Even Written
                        <br>
                        <strong>Speaker: </strong><a href="http://people.ischool.berkeley.edu/~nakov/">Preslav Nakov</a>
                        <br>
                        <br>
                        <strong> Abstract: </strong>
                        Given the recent proliferation of disinformation online, there has been also growing research
                        interest in automatically debunking rumors, false claims, and "fake news". A number of
                        fact-checking initiatives have been launched so far, both manual and automatic, but the whole
                        enterprise remains in a state of crisis: by the time a claim is finally fact-checked, it could
                        have reached millions of users, and the harm caused could hardly be undone. An arguably more
                        promising direction is to focus on fact-checking entire news outlets, which can be done in
                        advance. Then, we could fact-check the news before they were even written: by checking how
                        trustworthy the outlets that published them are.

                        We will show how we do this in the Tanbih news aggregator (http://www.tanbih.org/), which makes
                        users aware of what they are reading. In particular, we develop media profiles that show the
                        general factuality of reporting, the degree of propagandistic content, hyper-partisanship,
                        leading political ideology, general frame of reporting, stance with respect to various claims
                        and topics, as well as audience reach and audience bias in social media.
                        <br>
                        <br>
                        <strong>Bio:</strong>
                        Dr. Preslav Nakov is a Principal Scientist at the Qatar Computing Research Institute (QCRI),
                        HBKU. His research interests include computational linguistics, "fake news" detection,
                        fact-checking, machine translation, question answering, sentiment analysis, lexical semantics,
                        Web as a corpus, and biomedical text processing. He received his PhD degree from the University
                        of California at Berkeley (supported by a Fulbright grant), and he was a Research Fellow in the
                        National University of Singapore, a honorary lecturer in the Sofia University, and research
                        staff at the Bulgarian Academy of Sciences. At QCRI, he leads the Tanbih project
                        (http://tanbih.qcri.org), developed in collaboration with MIT, which aims to limit the effect of
                        "fake news", propaganda and media bias by making users aware of what they are reading. Dr. Nakov
                        is the Secretary of ACL SIGLEX and of ACL SIGSLAV, and a member of the EACL advisory board. He
                        is member of the editorial board of TACL, C&SL, NLE, AI Communications, and Frontiers in AI. He
                        is also on the Editorial Board of the Language Science Press Book Series on Phraseology and
                        Multiword Expressions. He co-authored a Morgan & Claypool book on Semantic Relations between
                        Nominals, two books on computer algorithms, and many research papers in top-tier conferences and
                        journals. He also received the Young Researcher Award at RANLP'2011. He was also the first to
                        receive the Bulgarian President's John Atanasoff award, named after the inventor of the first
                        automatic electronic digital computer. Dr. Nakov's research was featured by over 100 news
                        outlets, including Forbes, Boston Globe, Aljazeera, MIT Technology Review, Science Daily,
                        Popular Science, Fast Company, The Register, WIRED, and Engadget, among others.
                        <br>
                        <br>
                    </div>

		    
<!--
                <div class="accordion" id="accordion">
                    <div class="table-responsive">
                        <table class="table">
                            <tbody>
                            <tr align="center">
                                <td>
                                    <a href="#rada" data-toggle="collapse">
                                        <figure>
                                            <img src="images/rada.jpg" class="hover2" width="150" height="192">
                                            <figcaption><h5>Rada Mihalcea</h5></figcaption>
                                        </figure>
                                    </a>
                                </td>
                            </tr>
                            </tbody>
                        </table>
                    </div>


                    <div id="rada" class="collapse" data-parent="#accordion">
                        <strong>Title: </strong> The Ups and Downs of Word Embeddings
                        <br>
                        <strong>Speaker: </strong><a href="https://web.eecs.umich.edu/~mihalcea/">Rada Mihalcea</a>
                        <br>
                        <br>
                        <strong> Abstract: </strong> Words are the central units of the languages we all speak. In a
                        similar way, word representations are the core units of the algorithms that we build to
                        automatically process language, and they form the foundation for many applications of natural
                        language processing, ranging from question answering systems, to chat bots, search engines, or
                        systems for machine translation. In this talk, I will take a deep dive into word embeddings, and
                        address two aspects of word embeddings. First, I will take a close look at their stability, and
                        show that even relatively high frequency words are often unstable. I will provide empirical
                        evidence for how various factors contribute to the stability of word embeddings, and analyze the
                        effects of stability on downstream tasks. Second, I will explore the relation between words and
                        people and show how we can develop cross-cultural word representations to identify words with
                        cultural influence, and also how we can effectively use information about the people behind the
                        words to build better word representations. This is joint work with Laura Burdick, Aparna
                        Garimella, Carmen Banea.

                        <br>
                        <br>
                        <strong>Bio:</strong> Rada Mihalcea is a Professor of Computer Science and Engineering at the
                        University of Michigan and the Director of the Michigan Artificial Intelligence Lab. Her
                        research interests are in computational linguistics, with a focus on lexical semantics,
                        multilingual natural language processing, and computational social sciences. She serves or has
                        served on the editorial boards of the Journals of Computational Linguistics, Language Resources
                        and Evaluations, Natural Language Engineering, Journal of Artificial Intelligence Research, IEEE
                        Transactions on Affective Computing, and Transactions of the Association for Computational
                        Linguistics. She was a program co-chair for EMNLP 2009 and ACL 2011, and a general chair for
                        NAACL 2015 and *SEM 2022. She currently serves as the ACL Vice-President Elect. She is the
                        recipient of a National Science Foundation CAREER award (2008) and a Presidential Early Career
                        Award for Scientists and Engineers awarded by President Obama (2009). In 2013, she was made an
                        honorary citizen of her hometown of Cluj-Napoca, Romania.
                        <br>
                        <br>
                    </div>
					-->
                </div>
            </div>
        </div>
</section>


<!--
<section id="panelists" class="bg-light">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <h3>Panel Discussions: Ethics in AI</h3>
                <p>
                    The following speakers have accepted to serve as panelists for the panel discussion at SSNLP 2023.
                    You can view their detailed
                    information by clicking the images. Eduard Hovy and other academic speakers will also be discussants
                    on the panel (TBC).
                </p>

                <div class="accordion" id="accordion2">
                    <div class="table-responsive">
                        <table class="table">
                            <tbody>
                            <tr align="center">
                                <td>
                                    <a href="#liling" data-toggle="collapse">
                                        <figure>
                                            <img src="images/liling.png" class="hover2" width="160" height="192">
                                            <figcaption><h5>Liling Tan</h5></figcaption>
                                        </figure>
                                    </a>
                                </td>
                                <td>
                                    <a href="#shafiq" data-toggle="collapse">
                                        <figure>
                                            <img src="images/shafiq.jpg" class="hover2" align="center" width="160"
                                                 height="192">
                                            <figcaption>
                                                <h5>Shafiq Joty</h5>
                                            </figcaption>
                                        </figure>
                                    </a>
                                </td>
                                <td>
                                    <a href="#guillermo" data-toggle="collapse">
                                        <figure>
                                            <img src="images/Guillermo.png" class="hover2" align="center" width="160"
                                                 height="192">
                                            <figcaption>
                                                <h5>Guillermo Infante</h5>
                                            </figcaption>
                                        </figure>
                                    </a>
                                </td>
                            </tr>
                            </tbody>
                        </table>
                    </div>


                    <div id="liling" class="collapse" data-parent="#accordion2">
                        <strong>Speaker: </strong><a href="https://www.linkedin.com/in/alvations/">Liling Tan</a>
                        <br>
                        <br>
                        <strong>Bio:</strong> Liling Tan is a Research Scientist at at Rakuten Institute of Technology
                        Singapore. Currently, he works on machine translation and language learning technologies.
                        Previously, he was an early stage researcher in Saarland University working on dictionaries,
                        ontologies and machine translation. Before that, he studied at NTU working on crosslingual
                        semantics and multilingual corpora.
                        <br>
                        <br>
                    </div>

                    <div id="shafiq" class="collapse" data-parent="#accordion2">
                        <strong>Speaker: </strong><a href="https://raihanjoty.github.io">Shafiq Joty</a>
                        <br>
                        <br>
                        <strong>Bio:</strong> Shafiq Joty is an Assistant professor at the School of Computer Science
                        and Engineering, NTU. He is also a senior research manager at Salesforce Research. He holds a
                        PhD in Computer Science from the University of British Columbia. His work has primarily focused
                        on developing language analysis tools (e.g., parsers, NER, coherence models), and exploiting
                        these tools effectively in downstream applications for question answering, machine translation,
                        image/video captioning and visual question answering. He was an area chair for ACL-2022 and
                        EMNLP-2022. He gave tutorials on ``Discourse Analysis and Its Applications" at ACL-2022 and at
                        ICDM-2018.
                        <br>
                        <br>
                    </div>

                    <div id="guillermo" class="collapse" data-parent="#accordion2">
                        <strong>Speaker: </strong><a href="https://www.linkedin.com/in/ginfante/?originalSubdomain=sg">Guillermo
                        Infante</a>
                        <br>
                        <br>
                        <strong>Bio:</strong> Guillermo Infante is the Chief Technology Officer of TAIGER, a global
                        Artificial Intelligence
                        company headquartered in Singapore with offices in five other countries across Europe, America
                        and Asia-Pacific.
                        He leads the technology team to develop cognitive solutions that help organisations to optimise
                        operational efficiencies. With over a decade in the computer science and software engineering
                        fields, Guillermo drives research and development projects with Artificial Intelligence and
                        Semantic Technologies.
                        Prior to join TAIGER, he worked as a professor at leading universities of Spain and Latin
                        America. He was also a researcher in the field of Semantics &amp; AI and his work contributed to
                        expand the knowledge base of several technology systems and industries.
                        His career interest is mainly on AI, Natural Language Processing and Understanding, as well as
                        Knowledge Representation and Reasoning. His work has been published in multiple peer-
                        reviewed international journals.
                        Guillermo holds a PhD in Computer Science and a MSc degree in Web Engineering from the
                        University of Oviedo (Spain), and an executive MSc degree in Innovation Management from the
                        EOI Business School (Madrid, Spain).
                        <br>
                        <br>
                    </div>


                </div>

            </div>
        </div>
    </div>
</section>
-->

<section id="organizers" class="bg-light">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <h2>Organizers</h2>

		<span>
                    <a href="http://nus.edu.sg/">
                        <img src="images/nus.png" width="190" style="margin-right: 30px">
                    </a>
                    <a href="https://www.ntu.edu.sg">
                        <img src="images/ntu.png" width="230" style="margin-right: 20px">
                    </a>
                    <a href="https://www.smu.edu.sg/">
                    <img src="images/smu.png" width="230" style="margin-right: 20px">
                    </a>
                    <a href="https://www.sutd.edu.sg/">
                        <img src="images/sutd.png" width="180" style="margin-left: 100px">
                    </a>
                    <a href="https://www.a-star.edu.sg/i2r">
                    <img src="images/i2r.png" width="190" style="margin-left: 120px">
                    </a>
                </span>
		   
                <p>
                    <table class="table">
                        <tbody>
		                <tr>
		                    <td>General Chair:</td>
		                    <td>
		                        <p><a href="https://kokiljaidka.wordpress.com"> Kokil Jaidka</a>, National University of Singapore</p>
		                    </td>
		                </tr>

		                <tr>
		                    <td>PC Chair:</td>
		                    <td>
		                        <p><a href="https://sites.google.com/view/gaowei"> Wei Gao</a>, Singapore Management University</p>
		                    </td>
		                </tr>

		                <tr>
		                    <td>Organizing Committee:</td>
		                    <td>
		                        <p><a href="https://wing.comp.nus.edu.sg/people/"> Yanxia Qin</a>,  National University of Singapore</p>
		                        <p><a href="http://haofei.vip/"> Hao Fei</a>,  National University of Singapore</p>
		                        <p><a href="https://dengyang17.github.io/"> Yang Deng</a>,  National University of Singapore</p>
		                        <p><a href="https://wing.comp.nus.edu.sg/people/"> Sun Shuo</a>,  Institute for Infocomm Research</p>
		                        <p><a href="https://suzyahyah.github.io/about/"> Suzanna Sia</a>,  Johns Hopkins University</p>
		                        <p><a href="#"> Gerard Yeo</a>,  National University of Singapore</p>
		                    </td>
		                </tr>

		                <tr>
		                    <td>Co-organizers:</td>
		                    <td>
		                        <p><a href="https://www.comp.nus.edu.sg/~kanmy">Min-Yen Kan</a>, National University of Singapore</p>
		                        <p><a href="https://www.comp.nus.edu.sg/~nght">Hwee Tou Ng</a>, National University of Singapore</p>
		                        <p><a href="https://www.chuatatseng.com/">Tat-Seng Chua</a>, National University of Singapore</p>
		                        <p><a href="https://raihanjoty.github.io">Shafiq Joty</a>, Nanyang Technological University</p>
		                        <p><a href="https://sites.google.com/site/nancyfchen/home">Nancy Chen</a>, Institute for Infocomm Research</p>
		                        <p><a href="http://www.colips.org/~sujian/">Jian Su</a>, Institute for Infocomm Research</p>
		                        <p><a href="http://www.mysmu.edu/faculty/jingjiang">Jing Jiang</a>, Singapore Management University</p>
		                        <p><a href="https://istd.sutd.edu.sg/people/faculty/lu-wei">Wei Lu</a>, Singapore University of Technology and Design</p>
		                        <p><a href="https://people.sutd.edu.sg/~sporia/">Soujanya Poria</a>, Singapore University of Technology and Design</p>
		                    </td>
		                </tr>

				
			</tbody>
                   </table>

                </p>
		    
            </div>
        </div>
    </div>
</section>


<section id="partners" class="bg-light">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <h2>Partners</h2>
                <br>
                <div class="spoil">
<!--                    <a href="https://www.sginnovate.com/"> <img src="images/sginnovate.jpg" width="150" height=""
                                                                style="margin-right: 50px"/></a>

                    <a href="http://www.tiktok.com/">  <img src="images/ssnlp/TikTok-logo-RGB-Horizontal-black.png.lin.png" width="200" height=""/></a>
					-->
                </div>
            </div>
        </div>
    </div>
</section>

<!--
<section id="photos" class="bg-light">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <h2>Photos</h2>
                <div id="carouselExampleIndicators" class="carousel slide" data-ride="carousel">
                    <ol class="carousel-indicators">
                        <li data-target="#carouselExampleIndicators" data-slide-to="0" class="active"></li>
                        <li data-target="#carouselExampleIndicators" data-slide-to="1"></li>
                    </ol>
                    <div class="carousel-inner">
                        <div class="carousel-item active">
                            <img class="d-block w-" src="images/ssnlp/hengji1.jpg" alt="First slide">
                        </div>
                        <div class="carousel-item">
                            <img class="d-block w-" src="images/ssnlp/hengji2.jpg" alt="Second slide">
                        </div>
                    </div>
                    <a class="carousel-control-prev" href="#carouselExampleIndicators" role="button" data-slide="prev">
                        <span class="carousel-control-prev-icon" aria-hidden="true"></span>
                        <span class="sr-only">Previous</span>
                    </a>
                    <a class="carousel-control-next" href="#carouselExampleIndicators" role="button" data-slide="next">
                        <span class="carousel-control-next-icon" aria-hidden="true"></span>
                        <span class="sr-only">Next</span>
                    </a>
                </div>
            </div>
        </div>
    </div>
</section>
-->

<section id="location" class="bg-light">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <h2>Location</h2>
                <p>
                 <b>SSNLP 2023</b> will be held at the <b>Shaw Foundation Alumni House Auditorium, NUS (11 Kent Ridge Dr, Singapore 119244)</b>.
                </p>
		<iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d3988.8020433844003!2d103.77080677592237!3d1.2932316617532535!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x31da1aff3f1cf5b1%3A0x7ae21f4141402cfd!2sShaw%20Foundation%20Alumni%20House!5e0!3m2!1sen!2ssg!4v1696739457238!5m2!1sen!2ssg" width="600" height="450" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>            </div>
        </div>
    </div>

</section>

<section id="past-ssnlp" class="bg-light">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <h2>Past SSNLP</h2>
                <ul>
		  <li>
                    · <a href="https://github.com/WING-NUS/SSNLP-2022">SSNLP 2022</a>.  Held at NUS.
                  </li>
                  <li>
                    · <a href="https://ssnlp.org/">SSNLP 2020</a>.  Held 100% virtually.
                  </li>
                  <li>
                    · <a href="https://wing-nus.github.io/SSNLP-2019">SSNLP 2019</a>. Held at I2R.
                  </li>
                  <li>
                    · <a href="https://event.statnlp.org/">SSNLP 2018</a>.  Inaugural event at SUTD.
                  </li>
                </ul>
                </p>
                <!--                <p id="h.p_Xe61aUT8vVF4" class="zfr3Q">Twitter: <a class="dhtgD"-->
                <!--                                                                   href="https://twitter.com/to-be-confirmed"-->
                <!--                                                                   target="_blank" rel="noopener">https://twitter.com/to-be-confirmed</a>-->
                <!--                </p>-->
                </p>
            </div>
        </div>
    </div>
</section>

<section id="contact" class="bg-light">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 mx-auto">
                <h2>Contact Us</h2>
                <p>
                <p id="h.p_4XXDjs_mNTFP" class="zfr3Q">Please feel free to reach out if you have any inquiries:			
                    <a href="mailto:yxqin@nus.edu.sg" target="_blank" rel="noopener">Yanxia Qin</a> and <a href="mailto:haofei37@nus.edu.sg" target="_blank" rel="noopener">Hao Fei</a>.
                </p>
            </div>
        </div>
    </div>
</section>

<footer class="py-5 bg-dark">
    <div class="container" style="text-align: center;">
        <!--        <a href="https://twitter.com/to-be-confirmed"><i class="fa fa-twitter fa-2x"></i></a>-->
        <!--        <a href="#"><i class="fa fa-facebook fa-2x"></i></a>-->
        <p><span style="color: white; ">Copyright &copy; SSNLP 2023 | <a href="https://wing.comp.nus.edu.sg/">NUS WING</a>
        </p>
    </div>
</footer>

<!-- Bootstrap core JavaScript -->
<script src="vendor/jquery/jquery.min.js"></script>
<script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

<!-- Plugin JavaScript -->
<script src="vendor/jquery-easing/jquery.easing.min.js"></script>

<!-- Custom JavaScript for this theme -->
<script src="js/scrolling-nav.js"></script>


<script src="vendor/bootstrap/js/popper.js"></script>
<script src="vendor/select2/select2.min.js"></script>
<script src="js/main.js"></script>

</body>

</html>
